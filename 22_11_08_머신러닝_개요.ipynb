{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAlI2GiMkOvl2hoE7SUfmi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/com0040/offline_alpaco/blob/main/22_11_08_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EA%B0%9C%EC%9A%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 리그레션 - 분류\n",
        "\n",
        "디시즌트리 - 앙상블\n",
        "\n",
        "나이브 - 베이즈"
      ],
      "metadata": {
        "id": "Z_TSMDWyj4tU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKxC2oEkj2Qm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수 -> 예측 \n",
        "\n",
        "기존 데이터의 상관관계(규칙성) : 방정식 X 아니라도 생각\n",
        "\n",
        "---\n",
        "\n",
        "기계 + 학습 : 뭘 학습??? -> 데이터??(데이터에서 뭘 학습??)\n",
        "\n",
        "### ** ⛹ 데이터간의 상관관계를 학습 ** \n",
        "\n",
        "hypothisis(하이퍼티티즈) : 상관관계 -> 상관관계식자체를 찾는다로는 모자라다.\n",
        "\n",
        "---\n",
        "\n",
        "상관관계식을 찾아줘~ X => 어떤 식인줄 알고 계수를 찾아달라고 하냐???\n",
        "\n",
        "-> 폼을 잡는 것은 우리가 해야한다. : 시켜야하는 것은 미지수를 알려달라하는 것.\n",
        "\n",
        "hypothisis(하이퍼티티즈) -> weight(가중치)\n",
        "\n",
        "잘못잡으면 어떻게해 ㅠㅠ ???\n",
        "\n",
        "---\n",
        "\n",
        "### 사람의 생각 순서\n",
        "\n",
        "    1. 단순한 구조를 먼저 생각한다. y = ax + b\n",
        "\n",
        "    2.  a = 10 이고 b = 0이네\n",
        "\n",
        "---\n",
        "\n",
        "아? 나는 못하는데... hypothisis를 집어넣는 판단력을 기르려고 공부하는 것이다.\n",
        "\n",
        "    1. 폼을 정한다.\n",
        "\n",
        "    2. 기계가 예측하게 넣는다.(weight를 학습 - weight를 찾는다.)\n",
        "\n",
        "---\n",
        "\n",
        "오차를 종합한 것 = cost\n",
        "\n",
        "    cost가 크면 hypothisis는 별로다\n",
        "\n",
        "    cost가 작으면 hypothsis는 좋다.\n",
        "\n",
        "    우리는 cost가 낮은 weight를 찾을 것이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "8LMQHZCRkaQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 머신러닝 \n",
        "\n",
        "\"머신러닝이 뭐야?\"\n",
        "\n",
        "= cost가 낮은 weight를 찾는 것.\n",
        "\n",
        "\"왜?\"\n",
        "\n",
        "1. cost가 낮다 -> 예측을 잘한다 : 예측과 실제의 오차가 작다.\n",
        "\n",
        "2. weight 찾기 -> hypothisis의 폼은 사람이 찾으니까.\n",
        "\n",
        "% dicisiontree는 weight를 갖지 앉는다.\n",
        "\n",
        "- 그렇지만 위의 정의로 쉽게 이해 할 수 있다.\n",
        "\n",
        "---\n",
        "\n",
        "min a / b  : a가 최소가 되게하는 b\n",
        "\n",
        "    min cost\n",
        "\n",
        "    w                 민 코스트 웨이트\n",
        "\n",
        "---\n",
        "지도 / 비지도 학습\n",
        "\n",
        "    데이터의 형태를 보면 안다. \n",
        "    정답을 알려주냐 아니냐(y값의 유무)\n",
        "\n",
        "---\n",
        "\n",
        "지도 학습\n",
        "\n",
        "    1. 회귀 : 숫자\n",
        "\n",
        "    2. 분류 : 카테고리\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xK0sRveDqUl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⏸ How min Cost / w ?? \n",
        "\n",
        "어떻게 찾느냐\n",
        "\n",
        "0. hypothisis의 폼을 우리가 결정해 준다. ex) y = ax + b\n",
        "\n",
        "    - x의 변화가 y의 변화를 유발하기보다 weight의 크기가 가중되서 가중치라고 한다.(상관계수라고도 한다. - coefficient)\n",
        "\n",
        "    - 한번에 찾을 수는 없다.\n",
        "\n",
        "1. 초기값 설정. \n",
        "\n",
        "2. Cost 확인 \n",
        "\n",
        "3. w 업데이트 : 언제찾아?? -> 방향이라도 알려달라.\n",
        "\n",
        "### ⛪ 중요한 것은 방향 How??? \n",
        "\n",
        "초기값 설치 후에 둘중 하나 -> 기울기, y 절편\n",
        "\n",
        "w - cost 관계 : cost는 weight에 의한 함수다.\n",
        "\n",
        "    기울기만 보고 그래프를 그려보면 최저점이 있고 다시 올라간다\n",
        "    초기값을 넣으면 w가 커져야 할지 작아져야할지 모르는데\n",
        "    찰나의 순간에서의 기울기는 계산 가능 - 미분\n",
        "\n",
        "기울기를 보면 cost가 낮아져야 하는 방향을 알 수 있다.\n",
        "\n",
        "기울기(Gradient) = G \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hfIVxkCmt3Mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G울기가 양수 / 음수 일때\n",
        "\n",
        "1. 양수 = cost랑 w가 같은 방향으로 가지 말아야한다. -> w 감소\n",
        "\n",
        "2. 음수 = w가 커지면 cost는 감소 -> w 증가\n",
        "\n",
        "현재 w = Wt -> G를 빼준다. ▶ W(t+1)\n",
        "\n",
        "---\n",
        "\n",
        "    방향은 맞는데 기울기가 커서 점점 멀어지는 현상이 나온다.\n",
        "\n",
        "    짧게 짧게 가야한다. -> 기울기를 빼는 건 맞는데 작은 수를 곱해준다.\n",
        "\n",
        "learning rate = 학습률 , w - update (어느정도로 작게 움직일 것이냐)\n",
        "\n",
        "- 중요하다. 하나만 수정한다면 learning rate.\n",
        "\n",
        "1. cost가 커진다 ? -> learning rate을 줄인다\n",
        "\n",
        "2. cost가 너무 느리게 작아진다 -> learning rate 조절\n",
        "\n",
        "        기울기 하강법(경사하강법) = Gradient Descent Algorithm\n",
        "        -> 공의 궤적 -> 힘을 주면 언덕을 넘어간다.\n",
        "    \n",
        "    현재기울기를 사용하는 것의 한계 -> momentum\n",
        "\n",
        "과거의 기울기를 기록해놓고\n",
        "\n",
        "-> 멈춰야지 - 관성(아까의 기울기의 일정량을 다음 기울기에 더해준다)\n",
        "\n",
        "현재의 기울기는 0(음수)이지만 오던게 있으니 진행한다. - 일단은 진행"
      ],
      "metadata": {
        "id": "N5PC78nb2zCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 잘 정리해놓자\n",
        "\n",
        "ML = min Cost / w \n",
        "\n",
        "How min Cost / w ??\n",
        "\n",
        "W(t+1) <- Wt - aG : \n",
        "\n",
        "---\n",
        "\n",
        "비계설정 -> 기초석\n",
        "\n",
        "-> 머신러닝 성능 개선 : 안나오는 상황 해석\n",
        "\n",
        "- 10만개 : 가격 예측 / 학습? 몇 개 [train / test] 8:2\n",
        "\n",
        "학습 x 테스트 x = 언더피팅(overfit)\n",
        "\n",
        "학습 o 테스트 x = 오버피팅(underfit)\n",
        "\n",
        "학습 o 테스트 o = fit\n",
        "\n",
        "---\n",
        "\n",
        "테스트가 안되는 경우 2가지(언더핏 오퍼핏) -> 첫번째 관문\n",
        "\n",
        "해결방법 -> 배워갈 것이다.\n",
        "\n",
        "- 데이터의 복잡도 : 1) 선형, 2) 비선형\n",
        "\n",
        "1. underfit = 경계선(모델)의 복잡도 < 데이터의 복잡도\n",
        "\n",
        "2. overfit = 경계선(모델)의 복잡도 > 데이터의 복잡도\n",
        "\n",
        "0단계) 모델 선택으로 해결\n",
        "\n",
        "or) 규제를 걸어 해결\n",
        "\n",
        "else) 전처리 -> 데이터의 복잡도 결정\n",
        "\n",
        "---\n",
        "\n",
        "### 모델성능 ⬆\n",
        "\n",
        "over/under fit을 해결 = 데이터/모델 복잡도의 조화를 맞춰서 해결\n",
        "\n",
        "## 정의, How, 성능 ? -> 머신러닝 잘해??"
      ],
      "metadata": {
        "id": "NYvOsRxgAtu9"
      }
    }
  ]
}