{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr77lACF98qaZG66ERQl+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/com0040/offline_alpaco/blob/main/22_11_04_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%A7%88%EC%9D%B4%EB%8B%9D_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 전처리\n",
        "- 전처리 기법 : 토큰화, 노이즈/불용어 제거, 통일화, 품사태깅, 벡터화\n",
        "- 위의 전처리 기법이 실제 분석에서 어떻게 이루어지는지 파악하고 익혀보자"
      ],
      "metadata": {
        "id": "OHCKAQM79Qdy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMhW6w0A8PIj",
        "outputId": "2215b791-09b8-4aca-e237-148138d59b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 22.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미 앞서 다뤄본 적이 있는 기본적인 라이브러리\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "uQYBInI29U4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt # komoran, hannanum, kkma, mecab"
      ],
      "metadata": {
        "id": "QoxcDb5GcS3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 왜 코드 재사용을 함수라고 부르는가\n",
        "\n",
        "1. 입력값, 출력값 = 함수와 닮았네\n",
        "\n",
        "2. 입력과 출력의 관계 -> 코드가 된다.\n",
        "\n",
        "- "
      ],
      "metadata": {
        "id": "T9R-eOUb-j-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(review):\n",
        "    okt = Okt()\n",
        "    \n",
        "    f = open('nsmc_stopwords.txt')\n",
        "    stop_words = f.read().split()\n",
        "    \n",
        "    # 1. 한글 및 공백을 제외한 문자 모두 제거.\n",
        "    review_text = re.sub(\"[^가-힣\\\\s]\", \"\", review)\n",
        "    \n",
        "    # 2. okt 객체를 활용해서 형태소 토큰화 + 품사 태깅\n",
        "    word_review = okt.pos(review_text, stem=True) # pos 품사태긱 / stem = 토큰화\n",
        "\n",
        "    # 노이즈 & 불용어 제거\n",
        "    word_review = [(token, pos) for token, pos in word_review if not token in stop_words and len(token) > 1]\n",
        "    \n",
        "    # 명사, 동사, 형용사 추출\n",
        "    word_review = [token for token, pos in word_review if pos in ['Noun', 'Verb', 'Adjective']]\n",
        "\n",
        "    return word_review"
      ],
      "metadata": {
        "id": "8kN3Cnxd_Q7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 변수 함수 클래스\n",
        "\n",
        "1. 변수 - 데이터를 담은 통\n",
        "\n",
        "2. 함수 - 코드를 담은 통\n",
        "\n",
        "3. 클래스 - 변수 , 함수 통\n",
        "\n",
        "▶ 재사용, 관리 : \n",
        "\n",
        "* 상식 : attribute -> 클래스안의 기능 / mathod -> 함수안의 기능\n",
        "\n"
      ],
      "metadata": {
        "id": "O_VqhjgnQ8ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/nsmc_stopwords.txt')\n",
        "stopwords = f.read().split()\n",
        "stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W3pL_zpTLP9",
        "outputId": "4e328533-1737-4d56-f38c-a7f249eeb70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['교도서', '스파이더맨', '이야기', '영화', '3D', '완전', '솔직히', '평점', '주다', '하다']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 폴더 경로\n",
        "\n",
        "\\content\\nsmc_stopwords.txt\n",
        "\n",
        "\\content\\sample_data\n",
        "\n",
        "1. 절대 경로 - 최상위경로부터 표현\n",
        "\n",
        "2. 상대 경로 - 현재 실행 파일 기준 상대적인 경로만 표현\n",
        "\n",
        "---\n",
        "\n",
        "    content\n",
        "        - a\n",
        "            - stopwords.txt\n",
        "            - 파이썬 실행파일\n",
        "        - b\n",
        "\n",
        "stopword.txv\n",
        "\n",
        "- 절대경로 : content/a/stopwords\n",
        "\n",
        "- 상대경로 : stopwords.txt (or) ./stopwords.txt\n",
        "\n",
        "./ : 현재 자기자신의 경로\n",
        "\n",
        "../ : 한단계 상위 경로(부모경로)"
      ],
      "metadata": {
        "id": "HytIk10mT1_C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SWx54BKTTL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 퀴즈\n",
        "\n",
        "    content\n",
        "    - a\n",
        "        - 파이썬 실행파일\n",
        "    - b\n",
        "        - stopwords.txt\n",
        "\n",
        "stopwords.txt\n",
        "\n",
        "절대경로 : content/b/stopwords\n",
        "\n",
        "상대경로 : ../b/stopwords\n",
        "\n",
        "---\n",
        "\n",
        "    content\n",
        "    - a\n",
        "        - stopwords.txt\n",
        "    - b\n",
        "        - 파이썬 실행파일 \n",
        "\n",
        "절대경로 : content/a/stopwords\n",
        "\n",
        "상대경로 : ../a/stopwords\n",
        "\n",
        "---\n",
        "\n",
        "    content\n",
        "    - 파이썬 실행파일\n",
        "    - a\n",
        "        - stopwords.txt\n",
        "    - b\n",
        "\n",
        "절대경로 : content/a/stopwords\n",
        "\n",
        "상대경로 : a/stopwords\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "C63mql0iVxDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/nsmc_stopwords.txt')\n",
        "stopwords = f.read().split()\n",
        "stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecph1wqoaUS_",
        "outputId": "393c7133-9fbd-44c5-caac-f3bebd90fa07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['교도서', '스파이더맨', '이야기', '영화', '3D', '완전', '솔직히', '평점', '주다', '하다']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 한글 및 공백을 제외한 문자 모두 제거.\n",
        "review_text = re.sub(\"[^가-힣\\\\s]\", \"\", '아.. 더빙 진짜 짜증나네')\n",
        "# 스페이스 한글 제외 -> 통째로 있을때 먼저 특문 버린다!\n",
        "review_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i88t2UoAaac9",
        "outputId": "15d60ce0-9388-40bf-dc2a-78abfa762f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'아 더빙 진짜 짜증나네'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "# 2. okt 객체를 활용해서 형태소 토큰화 + 품사 태깅\n",
        "word_review = okt.pos(review_text, stem=True)\n",
        "word_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5uKZfNwcGRS",
        "outputId": "e98d2ca5-359f-4878-c517-ec859946475b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('아', 'Exclamation'), ('더빙', 'Noun'), ('진짜', 'Noun'), ('짜증나다', 'Adjective')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos 결과 이해하기\n",
        "\n",
        "## 1. word_review에서 '더빙'만 출력해보자.\n",
        "\n",
        "## 2. 품사들만 출력해보자.\n",
        "\n",
        "## 토큰은 tokens에 품사는 pos에 리스트로 각각 담아보자."
      ],
      "metadata": {
        "id": "FoCgOUVVcZgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. word_review에서 '더빙'만 출력해보자.\n",
        "\n",
        "word_review[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O_KYNdWFc-Pm",
        "outputId": "899a0540-ffbc-44aa-fc5f-8a58bd97b293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'더빙'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. 품사들만 출력해보자.\n",
        "# for i in word_review :\n",
        "#     print(i[1])\n",
        "\n",
        "pos = [i[1] for i in word_review]\n",
        "pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8iIj38edHxy",
        "outputId": "6cb56eef-8c51-48e9-c36e-7399480a6994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Exclamation', 'Noun', 'Noun', 'Adjective']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 토큰은 tokens에 품사는 pos에 리스트로 각각 담아보자.\n",
        "\n",
        "# tokens, pos = [],[]\n",
        "# for i in word_review:\n",
        "#     tokens.append(i[0])\n",
        "#     pos.append(i[1])\n",
        "# tokens\n",
        "\n",
        "tokens = [i[0] for i in word_review]\n",
        "pos = [i[1] for i in word_review]\n",
        "print(tokens, pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pHXx6j1eERP",
        "outputId": "7e3ea178-d2b7-4428-c4b4-996720aba4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['아', '더빙', '진짜', '짜증나다'] ['Exclamation', 'Noun', 'Noun', 'Adjective']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "불용어 -> 날리겠다\n",
        "\n",
        "if 문 --> 포함 / 비포함"
      ],
      "metadata": {
        "id": "yEp6rVXzcGxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 노이즈 & 불용어 제거\n",
        "\n",
        "word_review = [(token, pos) for token, pos in word_review if not token in stopwords and len(token) > 1]\n",
        "# 불용어 사전에 없거나 1보다 긴 단어만 취급할 것이다."
      ],
      "metadata": {
        "id": "PNB5fZTN5DRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 벡터화 \n",
        "1. BoW : CountVectorizer\n",
        "2. TF-IDF : TfidfVectorizer"
      ],
      "metadata": {
        "id": "LU-o5ytT6bTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. BoW\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# bow = CountVectorizer(tokenizer=preprocessing, min_df=5, max_df=0.5) \n",
        "# 문서 빈도수 document freqeuncy 최소 5번 등장 -> 희소표현 \n",
        "# 너무 많으면 유의미한 단어로 안보기 위해 맥스값 비율로 넣는다.\n",
        "# 토큰화 안된 데이터를 넣는다 왜냐 전처리하는 함수도 넣을 것이기 때문에\n",
        "# 후에 백터라이저를 해라\n",
        "\n",
        "# 전처리기들의 특징 -> 변형기 \n",
        "# 1.fit = 세팅 (전처리기) - 우리들 것만 가지고 만드는 것 : 피처를 만들 것 \n",
        "# 2.transform (변형기) - 생성된 피처로 구성된 것을 숫자로 변형 (리뷰가 쌓이면)\n",
        "# 3.fit_transfrom (둘 다 수행) - 포함되지 않는 새로운 토큰은 버린다.\n",
        "# X_train_bow = bow.fit_transform(X_train)\n",
        "# X_train_bow = bow.fit(X_train)\n",
        "# X_test_bow = bow.transform(X_test) # 핏이 들어가면 치팅"
      ],
      "metadata": {
        "id": "Khk0EmU46cII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CountVectorizer?"
      ],
      "metadata": {
        "id": "F0xBPKD79U3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_features=2000 - 끊어주는 것이다.\n",
        "tfidf = TfidfVectorizer(tokenizer=preprocessing, max_features=2000, min_df=5, max_df=0.5) \n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "X_train_tfidf.toarray()"
      ],
      "metadata": {
        "id": "fZlUeYG-9W6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 및 검증\n",
        "- 현재 머신러닝 모델링에 대해 배운 것은 없지만,  \n",
        "- 전처리된 데이터를 통해 여러 모델에 학습이 가능하다는 것을 확인하는 정도로 코드를 이해해보자."
      ],
      "metadata": {
        "id": "avxuiem3ER2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 1 : Logistic Regression 모형\n",
        "from sklearn.linear_model import LogisticRegression # 분류 모델 : 확률적으로 계산(분류)하겠다.\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "log_clf.fit(X_train_tfidf, y_train)\n",
        "print('Train set score: {:.3f}'.format(log_clf.score(X_train_tfidf, y_train))) # naive\n",
        "print('Test set score: {:.3f}'.format(log_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "XitWEFerEScn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 지도 vs 비지도\n",
        "\n",
        "정답의 유무\n",
        "\n",
        "---\n",
        "\n",
        "만드는 목적에따라 -> y값을 넣냐 안넣냐\n",
        "\n",
        "---\n",
        "\n",
        "리뷰 예측 \n",
        "\n",
        ": 정답을 알려줘야 예측할 수 있다\n",
        "\n",
        "---\n",
        "\n",
        "x끼리 상관관계 = 비지도학습(상용화 어렵다)\n",
        "\n",
        "    NLP쪽은 다르긴함"
      ],
      "metadata": {
        "id": "mVciD0D7FnzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 2 : 트리 앙상블 모형\n",
        "from sklearn.ensemble import RandomForestClassifier # 나랑 같징않은 스터디\n",
        "\n",
        "model_rf = RandomForestClassifier(n_estimators = 100, max_depth=30, random_state = 0)\n",
        "# 깊이 30 \n",
        "model_rf.fit(X_train_tfidf, y_train)\n",
        "print('Train set score: {:.3f}'.format(model_rf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(model_rf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "Q0naMGTyIbv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 3 : Naive Bayes 분류모형\n",
        "from sklearn.naive_bayes import MultinomialNB # 총 3가지\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=0.1)\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "pRaXquZkKLZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델\n",
        "\n",
        "1. 선형적 = 단순하다\n",
        "\n",
        "2. 비선형적 = 복잡하다\n",
        "\n",
        "---\n",
        "\n",
        "무조건 좋은 모델 ? ㄴ\n",
        "\n",
        "단순 문제 = 단순 모델\n",
        "\n",
        "복잡 문제 = 복잡 모델\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "데이터 vs 모델 : 전처리를 많이하면 단순하게 만들어\n",
        "\n",
        "단순한 모델에 넣어\n",
        "\n",
        "설계 - 계획대로 : 성능개선을 위한 구체화 (데이터 + 모델 = 가장 핏)\n",
        "\n",
        "---\n",
        "\n",
        "딥러닝 - 복잡(0)"
      ],
      "metadata": {
        "id": "leSK6S60KkCR"
      }
    }
  ]
}