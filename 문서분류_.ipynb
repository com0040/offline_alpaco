{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhlcrH3k3whMax5+L3nche",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/com0040/offline_alpaco/blob/main/%EB%AC%B8%EC%84%9C%EB%B6%84%EB%A5%98_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|    | overfit | underfit |\n",
        "|---|---|---|\n",
        "|데이터핸들링 | 데이터복잡도 🔼, 차원 🔽, 양 🔼|데이터 복잡도 🔽 |\n",
        "|모델|모델복잡도🔽, 규제화(cost 재정의), 단순한 모델 선택|모델복잡도 🔼|\n",
        "\n",
        "\n",
        "\n",
        "- 차원이 준다 = 적은 정보로 맞추게 한다. / 어렵게 학습시킴\n",
        "\n",
        "- 오차 최소화 전략 -> 오버핏이 될 수 있다.(일반화를 하면서 공부해라) => 규제화\n",
        "\n",
        "    \n",
        "    규제화 = 오차 + 모델복잡도 (모델복잡도를 정의할 수 있어야함!!)\n",
        "\n",
        "How?? ▶ weight의 크기를 계산하면 복잡한 모델일수록 크다.\n",
        "\n",
        "벡터의 크기 = 제곱하고 더하는것 (L2norm)\n",
        "\n",
        "규제를 걸면 weight의 크기가 준다.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "u6e05YqBajI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AkKt0XNagtb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문서분류\n",
        "\n",
        "- 분류모델 (지도 / 카테고리)\n",
        "\n",
        "    1. 확률적 / 비확률적\n",
        "\n",
        "    2. 선형 / 비선형 : 분류하는 경계선이 (선현/비선형)\n"
      ],
      "metadata": {
        "id": "qNt16gCZnukc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "\n",
        "0에서 1사이에 수렴하는 함수 \n",
        "\n",
        "Logistic = 확률적 분류\n",
        "\n",
        "Regression = 선형적 모형\n",
        "\n",
        "⚾ 뭐가 선형일까? -> 분류하는 구분선(경계선)\n",
        "\n",
        "뭐가 좋은 건데?? -> 선형 문제 = 선형 모델, 비선형 (복잡 - 복잡 비선형, 단순 - 단순 비선형)\n",
        "\n",
        "---\n",
        "\n",
        "모델 구현에 초점을 맞춘다. -> 모델을 공부해야하는데...\n",
        "\n"
      ],
      "metadata": {
        "id": "s65dAf6botDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 공부의 초점\n",
        "\n",
        "1. Hypothisis : x와 y의 상관관계. (의미하는 바는?) -> x를 입력받아서 y를 어떻게 예측할 것인가??\n",
        "\n",
        "2. Cost Function : 정리(학습방식) -> 리딩만되면 넘어갈 수 있음\n",
        "\n",
        "---\n",
        "\n",
        "로지스틱 회귀분석\n",
        "\n",
        "- 선형적, 확률적 : 수식을 이해하기 전에 알아둘 것.\n",
        "\n",
        "1. 경계선을 찾아 \n",
        "\n",
        "2. 확률적으로 예측\n",
        "\n",
        "    \n",
        "    수식으로 표현하기만 하면 된다.\n",
        "\n",
        "    Wx = 0 / \"선형 경계선\" 찾고\n",
        "\n",
        "    확률적으로 예측하기\n",
        "\n",
        "    1 / (1+ e^(-wx)) -> 0에서 1사이에 수렴하는 \"로지스틱 함수\" (시그모이드의 일종)\n",
        "\n",
        "♐ 함수설명\n",
        "\n",
        "hypothisis\n",
        "\n",
        "    1 y = e^x \n",
        "    2 y = e^(-x) \n",
        "    3 y = e^(-x) +1 \n",
        "    4 y = 1 /e^(-x) +1"
      ],
      "metadata": {
        "id": "n1j61vvYrpQS"
      }
    }
  ]
}